---
title: What is ComfyUI?
description: "Build sophisticated GenAI applications without coding using visual workflows and production deployment"
icon: "palette"
---


## What is ComfyUI?

ComfyUI is a visual programming interface for building AI workflows using drag-and-drop nodes. Create sophisticated image, video, text, and audio generation workflows without coding. FlowScale AI deploys these workflows as production APIs.

<Frame>
  <img
    src="/images/glossary/comfyui-workflow-to-api-comparison.png"
    alt="Side-by-side comparison showing ComfyUI workflow interface and its deployed API"
  />
</Frame>

{/* Image Description for Team: Split-screen screenshot showing ComfyUI workspace with complex workflow on left and clean API interface on right with transformation arrows */}


<Frame>
  <img
    src="/images/glossary/comfyui-node-workspace-overview.png"
    alt="ComfyUI node workspace showing visual programming interface for AI workflows"
  />
</Frame>

{/* Image Description for Team: Screenshot of ComfyUI workspace showing clean visual programming interface with nodes, connections, and basic workflow example */}

## Core Capabilities

<Frame>
  <img
    src="/images/glossary/comfyui-multimodal-workflow.png"
    alt="ComfyUI interface displaying multi-modal workflow with text, image, and video processing nodes"
  />
</Frame>

{/* Image Description for Team: Screenshot of ComfyUI workspace showing multiple connected node chains for text, image, and video processing with clear data flow between AI models */}

<CardGroup cols={2}>
  <Card title="Beyond Images" icon="sparkles">
    Build complex workflows for **images, videos, audio, and text generation**—all in one interface
  </Card>
  <Card title="Complex Logic Made Simple" icon="brain">
    Create conditional workflows, multi-step pipelines, and advanced AI operations without coding
  </Card>
  <Card title="Drag-and-Drop Power" icon="hand">
    Each block (called a *node*) does one specialized job—combine them to build enterprise-grade GenAI solutions
  </Card>
  <Card title="Universal Compatibility" icon="globe">
    Works with any AI model, custom nodes, and runs anywhere—Windows, macOS, Linux, or cloud
  </Card>
</CardGroup>

Key features:

- **Visual Programming**: Connect nodes instead of writing code
- **Multi-modal**: Support for images, videos, audio, and text
- **Real-time Editing**: Modify workflows and see results instantly
- **Community Extensions**: Thousands of custom nodes available

[SCREENSHOT: Close-up of ComfyUI node connections showing data flow between a text prompt node, model loader, sampler, and output node with visible connection lines]

## FlowScale AI Integration

FlowScale AI converts ComfyUI workflows into production APIs with auto-scaling infrastructure, monitoring, and security.

[SCREENSHOT: FlowScale AI deployment interface showing the "Deploy" button and resulting API endpoint URL and web playground link]

<CardGroup cols={2}>
  <Card title="Visual Development" icon="palette">
    Build complex workflows without coding
  </Card>
  <Card title="Production Deployment" icon="rocket">
    Deploy as scalable APIs and web interfaces
  </Card>
  <Card title="Managed Infrastructure" icon="server">
    Auto-scaling GPUs and monitoring
  </Card>
  <Card title="Complete Solution" icon="stack">
    From prototype to production without code
  </Card>
</CardGroup>

[SCREENSHOT: Before/after timeline showing traditional development (6 months, multiple teams) vs ComfyUI + FlowScale AI (3 days, single person)]

## Use Cases

<CardGroup cols={2}>
  <Card title="AI Art Platform" icon="image">
    **ComfyUI**: Multi-style image generation with LoRA switching
    **FlowScale**: Web playground where users generate custom art via simple prompts
  </Card>
  <Card title="Video Processing API" icon="video">
    **ComfyUI**: Video-to-video transformation with face swapping
    **FlowScale**: REST API that processes uploaded videos and returns results
  </Card>
  <Card title="Content Creation Tool" icon="pen-nib">
    **ComfyUI**: Text-to-image + upscaling + background removal pipeline
    **FlowScale**: Web app for marketers to create social media content
  </Card>
  <Card title="Custom AI Chatbot" icon="robot">
    **ComfyUI**: Multi-model text generation with memory and context
    **FlowScale**: Embeddable chat widget for websites
  </Card>
</CardGroup>

## Workflow Structure

Workflows consist of connected nodes that process data:

<Steps>
  <Step title="Input nodes">
    Load models and define prompts
  </Step>
  <Step title="Processing nodes">
    Apply samplers, upscalers, and transformations
  </Step>
  <Step title="Output nodes">
    Save or display results
  </Step>
</Steps>


[SCREENSHOT: ComfyUI workspace showing invalid connection attempt with red warning indicator and valid connection with green highlight]

## Key Concepts

| Term | Think of it as... | Why it matters |
|------|-------------------|----------------|
| **Node** | A single LEGO® brick | Does one job (e.g., "Load model") |
| **Workflow** | The finished LEGO® set | Runs the whole image pipeline. Saved as `.json` |
| **Model / Checkpoint** | A cookbook | Holds all the AI knowledge—whether for images, text, video, or audio |
| **Custom Node** | A fan-made LEGO® piece | Community add-ons—try new ideas without waiting for official updates |
| **Pod (FlowScale)** | A line cook in the cloud | Executes your workflow on a rented GPU |

## Basic Workflow Example

<Steps>
  <Step title="Load Model">
    Choose your AI model (SDXL for images, LLaMA for text, etc.)
  </Step>
  <Step title="Add Input">
    Enter your text prompt
  </Step>
  <Step title="Configure Processing">
    Set parameters like steps, strength, and sampling method
  </Step>
  <Step title="Process Output">
    Convert output to desired format
  </Step>
  <Step title="Save Results">
    Output saved to results folder
  </Step>
</Steps>


[SCREENSHOT: Successful workflow execution showing the generated output (Jaipur's Hawa Mahal image) alongside the completed workflow with all nodes in green "executed" state]

## Essential Terms

<AccordionGroup>
  <Accordion title="Prompt">
    Text that describes the image you want
  </Accordion>
  <Accordion title="Checkpoint">
    The big file that stores the AI model's brain
  </Accordion>
  <Accordion title="Sampler">
    The method that slowly sharpens the noisy blob into a picture
  </Accordion>
  <Accordion title="LoRA">
    A small add-on file that teaches the model a new style or character
  </Accordion>
  <Accordion title="Pod (FlowScale)">
    A cloud worker that runs your workflow
  </Accordion>
</AccordionGroup>

## Learning Resources

<Card
  title="ComfyUI Official Documentation"
  icon="external-link"
  href="https://docs.comfy.org"
  color="#60a5fa"
>
  Comprehensive guides and API references for mastering ComfyUI
</Card>

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Workflow Basics"
    icon="play"
    href="/workspace/overview"
  >
    Learn fundamental workflow concepts
  </Card>
  <Card
    title="Build Your First Workflow"
    icon="hammer"
    href="/get-started/build"
  >
    Step-by-step tutorial to create your first workflow
  </Card>
  <Card
    title="Deploy to Production"
    icon="rocket"
    href="/get-started/deploy"
  >
    Transform your workflow into a production API
  </Card>
  <Card
    title="Community Resources"
    icon="users"
    href="https://docs.comfy.org"
  >
    Official ComfyUI documentation and community
  </Card>
</CardGroup>

